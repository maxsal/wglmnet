#' Weighted random forest prediction models for weighted data via ranger
#'
#'@description This function allows as to fit random forest prediction (linear or logistic) models to weighted data, considering sampling weights in the estimation process and selects the mtry and min.node.size that minimizes the error based on different replicating weights methods.
#'
#' @param data A data frame with information about the response variable and covariates, as well as sampling weights and strata and cluster indicators. It could be \code{NULL} if the sampling design is indicated in the \code{design} argument.
#' @param col.y A numeric value indicating the number of the column in which information on the response variable can be found or a character string indicating the name of that column.
#' @param col.x A numeric vector indicating the numbers of the columns in which information on the covariates can be found or a vector of character strings indicating the names of these columns.
#' @param cluster A character string indicating the name of the column with cluster identifiers. It could be \code{NULL} if the sampling design is indicated in the \code{design} argument.
#' @param strata A character string indicating the name of the column with strata identifiers. It could be \code{NULL} if the sampling design is indicated in the \code{design} argument.
#' @param weights A character string indicating the name of the column with sampling weights. It could be \code{NULL} if the sampling design is indicated in the \code{design} argument.
#' @param design An object of class \code{survey.design} generated by \code{survey::svydesign()}. It could be \code{NULL} if information about \code{cluster}, \code{strata}, \code{weights} and \code{data} are given.
#' @param family A character string indicating the family to fit LASSO models. Choose between \code{gaussian} (to fit linear models) or \code{binomial} (for logistic models).
#' @param mtry_grid A vector of values to try for mtry paramter. Default is c(floor(p/3), floor(sqrt(p)), floor(sqrt(p)*2), floor(sqrt(p)*0.5)) where p is the number of exposures (i.e., length(col.x)).
#' @param min.node.size_grid A vector of values to try for min.node.size. Default is c(1, 3, 5, 10).
#' @param num_trees Number of trees to grow in forest
#' @param case_level A character string indicating the level of the response variable to be considered as the positive case. Default is "1".
#' @param splitrule Splitrule for forest. Default is default in ranger based on data.
#' @param importance method for selecting variable importance. default is "permutation"
#' @param write.forest whether to write the forest model in output. default is TRUE
#' @param method A character string indicating the method to be applied to define replicate weights. Choose between one of these: \code{JKn}, \code{dCV}, \code{bootstrap}, \code{subbootstrap}, \code{BRR}, \code{split}, \code{extrapolation}.
#' @param k A numeric value indicating the number of folds to be defined. Default is \code{k=10}. Only applies for the \code{dCV} method.
#' @param R A numeric value indicating the number of times the sample is partitioned. Default is \code{R=1}. Only applies for \code{dCV}, \code{split} or \code{extrapolation} methods.
#' @param B A numeric value indicating the number of bootstrap resamples. Default is \code{B=200}. Only applies for \code{bootstrap} and  \code{subbootstrap} methods.
#' @param dCV.sw.test A logical value indicating the method for estimating the error for \code{dCV} method. \code{FALSE}, (the default option) estimates the error for each test set and defines the cross-validated error based on the average strategy. Option \code{TRUE} estimates the cross-validated error based on the pooling strategy
#' @param train.prob A numeric value between 0 and 1, indicating the proportion of clusters (for the method \code{split}) or strata (for the method \code{extrapolation}) to be set in the training sets. Default is \code{train.prob = 0.7}. Only applies for \code{split} and \code{extrapolation} methods.
#' @param method.split A character string indicating the way in which replicate weights should be defined in the \code{split} method. Choose one of the following: \code{dCV}, \code{bootstrap} or \code{subbootstrap}. Only applies for \code{split} method.
#' @param print.rw A logical value. If \code{TRUE}, the data set with the replicate weights is saved in the output object. Default \code{print.rw=FALSE}.
#' @param verbose A logical value indicating whether to print messages about the progress of the function.
#'
#' @importFrom graphics abline mtext
#' @importFrom stats as.formula coef predict runif
#' @importFrom ranger ranger
#' @importFrom cli cli_progress_bar cli_progress_update cli_progress_done
#'
#' @return The output object of the function \code{wranger()} is an object of class \code{wranger}. This object is a list containing 3 or 4 elements, depending on the value set to the argument \code{print.rw}. Below we describe the contents of these elements:
#' - `param`: A list containing information of two elements:
#'   - `grid`: A numeric vector indicating all the values considered for the tuning parameter.
#'   - `min`: A numeric value indicating the value of the tuning parameters that minimizes the average error (i.e., selected optimal tuning parameter).
#' - `error`: A list containing information of two elements:
#'   - `average`: A numeric vector indicating the average error corresponding to each tuning parameter.
#'   - `all`: A numeric matrix indicating the error of each test set for each tuning parameter.
#' - `model`: A model fitted with optimal tuning paramters
#' - `data.rw`: A data frame containing the original data set and the replicate weights added to define training and test sets. Only included in the output object if \code{print.rw=TRUE}.
#' - `call`: an object containing the information about the way in which the function has been run.
#' @export
#'
#' @examples
#' data(simdata_lasso_binomial)
#' mcv <- wlasso(data = simdata_lasso_binomial,
#'               col.y = "y", col.x = 1:50,
#'               family = "binomial",
#'               cluster = "cluster", strata = "strata", weights = "weights",
#'               method = "dCV", k=10, R=20)
wranger <- function(
    data = NULL,
    col.y = NULL,
    col.x = NULL,
    cluster = NULL,
    strata = NULL,
    weights = NULL,
    design = NULL,
    family = "binomial",
    mtry_grid             = NULL,
    min.node.size_grid    = NULL,
    num_trees             = 500,
    case_level = "1",
    splitrule = NULL,
    importance   = "permutation",
    write.forest = TRUE,
    method = "dCV",
    k = 10,
    R = 1,
    B = 200,
    dCV.sw.test = FALSE,
    train.prob = 0.7,
    method.split = c("dCV", "bootstrap", "subbootstrap"),
    print.rw = FALSE,
    verbose = TRUE
) {

  # Stops and messages:
  if(is.null(data) & is.null(design)){stop("Information about either the data set ('data') or the sampling design ('design') needed.")}

  if(method == "split"){
    if(is.null(train.prob)){stop("Selected replicate weights method: 'split'.\nPlease, set a value between 0 and 1 for the argument 'train.prob'.")}
    if(train.prob < 0 | train.prob > 1){stop("Selected replicate weights method: 'split'.\nPlease, set a value between 0 and 1 for the argument 'train.prob'.")}
    if(length(method.split)!=1){stop("Selected replicate weights method: 'split'.\nPlease, set a valid method for the argument 'method.split'. Choose between: 'dCV', 'bootstrap' or 'subbootstrap'.")}
  }

  if(method == "extrapolation"){
    if(is.null(train.prob)){stop("Selected replicate weights method: 'extrapolation'.\nPlease, set a value between 0 and 1 for the argument 'train.prob'.")}
    if(train.prob < 0 | train.prob > 1){stop("Selected replicate weights method: 'extrapolation'.\nPlease, set a value between 0 and 1 for the argument 'train.prob'.")}
  }

  if(method %in% c("JKn", "bootstrap", "subbootstrap", "BRR")){
    if(R!=1){cat("Selected method:", method,". For this method, R = 1. Thus, the argument R =",R, "has been ignored.")}
  }

  if(method %in% c("dCV", "split", "extrapolation")){
    if(R != round(R)){stop("The argument 'R' must be an integer greater or equal to 1. R=",R," is not an integer.\nPlease, set a valid value for 'R' or skip the argument to select the default option R=1.")}
    if(R < 1){stop("The argument 'R' must be an integer greater or equal to 1. R=",R," lower than 1.\nPlease, set a valid value for 'R' or skip the argument to select the default option R=1.")}
  }

  if(method != "dCV"){
    if(!is.null(k) & k!=10){cat("Selected method:", method,". The argument k =",k, "is not needed and, hence, has been ignored.")}
  }

  if(method == "dCV"){
    if(k != round(k)){stop("The argument 'k' must be an integer. k=",k," is not an integer.\nPlease, set a valid value for 'k' or skip the argument to select the default option k=10.")}
    if(k < 1){stop("The argument 'k' must be a positive integer. k=",k," is not a positive integer.\nPlease, set a valid value for 'k' or skip the argument to select the default option k=10.")}
  }

  if(!(method %in% c("bootstrap", "subbootstrap"))){
    if(!is.null(B) & B!=200){cat("Selected method:", method,". The argument B =",B, "is not needed and, hence, has been ignored.")}
  }

  if(method %in% c("bootstrap", "subbootstrap")){
    if(B != round(B)){stop("The argument 'B' must be an integer. B=",B," is not an integer.\nPlease, set a valid value for 'B' or skip the argument to select the default option B=200.")}
    if(B < 1){stop("The argument 'B' must be a positive integer. B=",B," is not a positive integer.\nPlease, set a valid value for 'B' or skip the argument to select the default option B=200.")}
  }

  if (verbose) {
    cli::cli_progress_step("Fitting weighted random forest")
    on.exit(cli::cli_progress_done())
  }

  # Step 0: Notation
  if(!is.null(design)){
    cluster <- as.character(design$call$ids[2])
    if(cluster == "1"){
      cluster <- NULL
    }
    strata  <- as.character(design$call$strata[2])
    weights <- as.character(design$call$weights[2])
    data    <- get(design$call$data)
  }


  # Step 1: Generate replicate weights based on the method
  newdata <- replicate.weights(data = data, method = method,
                               cluster = cluster, strata = strata, weights = weights,
                               k = k, R = R, B = B,
                               train.prob = train.prob, method.split = method.split,
                               rw.test = TRUE, dCV.sw.test = dCV.sw.test)


  # Step 2: initialize parameter grid and create formula
  if (is.null(mtry_grid)) {
    p <- ncol(data) - 1
    mtry_grid <- floor(sqrt(p) * c(0.25, 0.5, 1, 2, 4))
  }
  if (is.null(min.node.size_grid)) {
    min.node.size_grid <- c(1, 3, 5, 10, 20)
    min.node.size_grid <- min.node.size_grid[min.node.size_grid < nrow(data)]
  }
  param_grid <- expand.grid(
    mtry          = mtry_grid,
    min.node.size = min.node.size_grid
  )
  if (is.null(col.x)) col.x <- names(data)[names(data) != outcome]
  f <- formula(paste0(outcome, " ~ ", paste0(col.x, collapse = " + ")))
  vars <- c(outcome, col.x)
  if (!is.factor(newdata[[outcome]])) newdata[[outcome]] <- as.factor(newdata[[outcome]])

  # Step 3: Fit the training models and estimate yhat for units in the sample
  rwtraincols <- grep("_train", colnames(newdata))
  l.yhat <- list()

  cli_progress_bar(name = "growing forests", type = "iterator", total = length(rwtraincols))
    for (col.w in rwtraincols) {
      pred_matrix <- matrix()
      for (i in 1:nrow(param_grid)) {
        model <- ranger::ranger(
          formula       = f,
          data          = newdata |> dplyr::select(tidyselect::all_of(vars)),
          num.tree      = num_trees,
          mtry          = param_grid[i, "mtry"],
          min.node.size = param_grid[i, "min.node.size"],
          case.weights  = newdata[[col.w]],
          splitrule     = splitrule,
          probability   = TRUE
        )

        if (nrow(pred_matrix) == 1) {
          pred_matrix <- matrix(ncol = 1, nrow = length(predict(model, newdata)$predictions))
          pred_matrix[, 1] <- predict(model, newdata, type = "response")$predictions[, case_level]
        } else {
          pred_matrix <- cbind(pred_matrix, predict(model, newdata, type = "response")$predictions[, case_level])
        }
    }
    # Sample yhat
    yhat <- pred_matrix
    l.yhat[[length(l.yhat) + 1]] <- yhat
    names(l.yhat)[[length(l.yhat)]] <- paste0("yhat_", colnames(newdata)[col.w])
    cli_progress_update()
    }
  cli_progress_done()

  # Step 4: estimate the error in the test sets
  error <- error.f(data = newdata, l.yhat = l.yhat,
                   method = method, cv.error.ind = dCV.sw.test,
                   R = R, k = k, B = B,
                   col.y = col.y, family = family, weights = weights)
  mean.error <- apply(error, 2, mean)

  param_min <- param_grid[which.min(mean.error), ]

  ranger_min <- ranger::ranger(
    formula       = f,
    data          = newdata,
    num.tree      = num_trees,
    mtry          = param_min[1, "mtry"],
    min.node.size = param_min[1, "min.node.size"],
    case.weights  = newdata[[weights]],
    importance    = importance,
    write.forest  = write.forest,
    splitrule     = splitrule,
    probability   = TRUE
  )

  result <- list()
  result$param <- data.table::data.table(
    parameter = paste0("wrf_", names(param_min)),
    value     = as.numeric(param_min)
  )
  result$param_grid <- param_grid
  result$error <- list(average = mean.error,
                       all = error)
  result$model <- ranger_min
  result$call <- ranger_min$call

  if(print.rw == TRUE){result$data.rw <- newdata}

  class(result) <- "wranger"

  return(result)

}
